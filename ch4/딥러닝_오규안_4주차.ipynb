{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce7eb37",
   "metadata": {},
   "source": [
    "# 4. 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c260541",
   "metadata": {},
   "source": [
    "* 학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cfa1e",
   "metadata": {},
   "source": [
    "## 4.1 데이터에서 학습한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4395f",
   "metadata": {},
   "source": [
    "* 신경망의 특징은 데이터를 보고 학습할 수 있습니다. (가중치 매개변수의 값을 데이터로 보고 자동으로 결정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe91a5",
   "metadata": {},
   "source": [
    "### 4.1.1 데이터 주도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b3b4b",
   "metadata": {},
   "source": [
    "* 기계학습은 데이터에서 답을 찾고 데이터에서 패턴을 발견하고 데이터로 이야기를 만듭니다. \n",
    "* 이미지를 인식하는 알고리즘을 만드려면, 이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5e254",
   "metadata": {},
   "source": [
    "### 4.1.2 훈련 데이터와 시험 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f1bf7",
   "metadata": {},
   "source": [
    "* 기계학습 문제는 범용 능력을 제대로 평가하기 위해 데이터를 훈련 데이터와 시험 데이터로 나눠 학습과 실험을 수행합니다. \n",
    "* 범용 능력은 보지 못한 데이터로도 문제를 올바르게 풀어내는 능력입니다. \n",
    "* 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾고, 시험 데이터를 사용하여 훈련한 모델의 실력을 평가합니다. \n",
    "* 한 데이터셋에 지나치게 최적화하면 오버피팅이 될 수도 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96780f7",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41906239",
   "metadata": {},
   "source": [
    "* 신경망은 '하나의 지표'를 기준으로 최적의 매개변수 값을 탐색합니다. \n",
    "* 신경망 학습에서 사용하는 지표는 손실 함수라고 합니다. \n",
    "* 손실 함수는 임의의 함수를 사용할 수도 있지만, 오차제곱합과 교차 엔트로피 오차를 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a484d",
   "metadata": {},
   "source": [
    "### 4.2.1 오차제곱합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0f76c",
   "metadata": {},
   "source": [
    "* 가장 많이 쓰이는 손실 함수는 오차제곱합입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bce519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88422f",
   "metadata": {},
   "source": [
    "* 원-핫 인코딩: 한 원소만 1로 하고, 그 외는 0으로 나타내는 표기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29e4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebcf3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1 : '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb6dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예2 : '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685909c3",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f05af",
   "metadata": {},
   "source": [
    "* 또 다른 손실 함수로서 교차 엔트로피 오차도 자주 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe0be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544fcaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486cbbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1fe950",
   "metadata": {},
   "source": [
    "* 오차제곱합의 판단과 일치합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c083d",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b77153",
   "metadata": {},
   "source": [
    "* MNIST 데이터셋은 훈련 데이터가 60,000개였습니다. 모든 데이터를 대상으로 손실 함수의 합을 구하려면 시간이 걸립니다.\n",
    "* 신경망 학습에서는 훈련 데이터로부터 일부만 골라 학습을 수행합니다. -> 미니배치 학습\n",
    "* 60,000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장만을 사용하여 학습하는 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b0cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Users\\\\user\\\\Downloads\\\\deeplearning_from_scratch-master\\\\deeplearning_from_scratch-master\")\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape) #훈련 데이터는 60,000개이고, 입력 데이터는 784얄인 것을 뜻합니다. \n",
    "print(t_train.shape) #훈련 데이터는 60,000개이고, 정답 레이블은 10줄짜리 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235ea1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) #지정한 범위의 수 중에서 무작위로 원하는 개수만큼 꺼낼 수 있습니다. \n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6c7e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13752,  3847, 53110,  2147, 47714, 16921,  8747, 24647, 59775,\n",
       "       32183])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf744ad",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a80ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b39ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18592a",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실 함수를 설정하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbd278",
   "metadata": {},
   "source": [
    "* 신경망 학습에서는 최적의 매개변수(가중치와 편향)를 탐색할 때 손실 함수의 값을 가능한 작게하는 매개변수 값을 찾습니다.\n",
    "* 매개변수의 미분(기울기)을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복합니다. \n",
    "* 신경망을 학습할 때 정확도를 지표로 삼아서는 안됩니다. 정확도를 지표로 하면, 매개변수의 미분이 대부분의 장소에서 0이 되기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8278b50",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d161d9c",
   "metadata": {},
   "source": [
    "### 4.3.1 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872819b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b86383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5f0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05722ee",
   "metadata": {},
   "source": [
    "* 아주 작은 차분으로 미분하는 것을 수치 미분이라 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcce2ca",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f5e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*2**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce1b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) # 0에서 20까지 0.1 간격의 배열 x를 만든다(20은 미포함).\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a664ebf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0999999999995449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca1baac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000065512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f01c2c",
   "metadata": {},
   "source": [
    "### 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd99028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "    # 또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c143ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537391db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d93c64",
   "metadata": {},
   "source": [
    "* 여럿인 함수에 대한 미분을 편미분이라 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb5df9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae8d649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c0119",
   "metadata": {},
   "source": [
    "## 4.4 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151b20c",
   "metadata": {},
   "source": [
    "* 모든 변수의 편미분을 벡터로 정리한 것은 기울기라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd16a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)  # x와 형상이 같은 배열을 생성\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "        x[idx] = tmp_val  # 값 복원\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22badba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e540299b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2d540bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e6751",
   "metadata": {},
   "source": [
    "### 4.4.1 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa7178",
   "metadata": {},
   "source": [
    "* 손실 함수는 매우 복잡하고, 매개변수 공간이 광대하여 어디가 최솟값이 되는 곳인지를 짐작할 수 없습니다.\n",
    "* 이런 상황에서 기울기를 잘 이용하여 함수의 최솟값을 찾으려는 것이 최솟값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0aafb",
   "metadata": {},
   "source": [
    "* 함수가 최솟값 안장점이 되는 장소에서는 기울기가 0입니다. \n",
    "* 경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동합니다. \n",
    "* 그런 다음 이동한 곳에서도 마찬가지로 기울기를 구하고, 또 기울어진 방향으로 나아가기를 반복합니다. \n",
    "* 이렇게 해서 함수의 값을 점차 줄이는 것이 경사법입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43273398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr* grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0034952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6693525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x = np.array([-3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "837bbeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d74ec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10.0\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)\n",
    "\n",
    "#학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902b8c8",
   "metadata": {},
   "source": [
    "### 4.4.2 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fad04a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Users\\\\user\\\\Downloads\\\\deeplearning_from_scratch-master\\\\deeplearning_from_scratch-master\\\\ch4.신경망 학습\\\\gradient_simplenet.py\")\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c292560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71651328  0.17803515  1.02608146]\n",
      " [-1.27364049 -0.11504121 -1.15048077]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W) # 가중치 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ade2822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.57618441  0.003284   -0.41978382]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2ae42bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최댓값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d65186bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0442456497024368"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1]) # 정답 레이블\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12e8605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca91b640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06643895  0.32238672 -0.38882567]\n",
      " [ 0.09965842  0.48358009 -0.5832385 ]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ff38304",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a6261",
   "metadata": {},
   "source": [
    "## 4.5 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a6c0f",
   "metadata": {},
   "source": [
    "### 전제\n",
    "* 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 학습이라 합니다. 신경망 학습은 다음가 같이 4단계로 수행합니다. \n",
    "\n",
    "### 1단계 - 미니배치\n",
    "* 훈련 데이터 중 일부를 무작위로 가져옵니다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표입닏. \n",
    "\n",
    "### 2단계 - 기울기 산출\n",
    "* 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시합니다. \n",
    "\n",
    "### 3단계 - 매개변수 갱신\n",
    "* 가중치 매개변수를 기울기 방향으로 아주 조금 갱신합니다. \n",
    "\n",
    "### 4단계 - 반복\n",
    "* 1~3단계를 반복합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd671a0",
   "metadata": {},
   "source": [
    "### 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4240c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Users\\\\user\\\\Downloads\\\\deeplearning_from_scratch-master\\\\deeplearning_from_scratch-master\\\\ch4.신경망 학습\\\\two_layer_net.py\")\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 weight_init_std=0.01):\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "            np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    # 예측을 한다.\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "\n",
    "    # 손실 함수를 구한다.\n",
    "    # x : 입력데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "\n",
    "        return cross_entropy_error(y, t)\n",
    "\n",
    "    # 정확도를 구한다.\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    # 매개변수의 기울기를 구한다.\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4c6c003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "net.params['W1'].shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14a33087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fcfccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['W2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45cf14b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['b2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b2623ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71ddc567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)  \n",
    "grads['W1'].shape\n",
    "grads['b1'].shape\n",
    "grads['W2'].shape\n",
    "grads['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda0a26",
   "metadata": {},
   "source": [
    "### 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea6352c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'two_layer_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12388\\621119650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\user\\\\Downloads\\\\deeplearning_from_scratch-master\\\\deeplearning_from_scratch-master\\\\ch4.신경망 학습\\\\two_layer_net.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtwo_layer_net\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'two_layer_net'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Users\\\\user\\\\Downloads\\\\deeplearning_from_scratch-master\\\\deeplearning_from_scratch-master\\\\ch4.신경망 학습\\\\two_layer_net.py\")\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=False)\n",
    "\n",
    "# 하이퍼 파라메터\n",
    "iters_num = 1000  # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100  # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    print(i)\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch)  # 다음 장에서 구현할 더 빠른 방법!\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7431528",
   "metadata": {},
   "source": [
    "### 4.5.3 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55bd882a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'two_layer_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12388\\3584472273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtwo_layer_net\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'two_layer_net'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=False)\n",
    "\n",
    "# 하이퍼 파라메터\n",
    "iters_num = 1000  # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100  # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    print(i)\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch)  # 다음 장에서 구현할 더 빠른 방법!\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "# 1에폭 당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \"\n",
    "              + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb82b0",
   "metadata": {},
   "source": [
    "## 4.6. 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4402341",
   "metadata": {},
   "source": [
    "### 이번 장에서 배운 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52c5cc",
   "metadata": {},
   "source": [
    "* 기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용합니다.\n",
    "* 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가합니다.\n",
    "* 신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신합니다.  \n",
    "* 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복합니다. \n",
    "* 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 합니다. \n",
    "* 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있습니다. \n",
    "* 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단합니다. 한편, 다음 장에서 구현하는 (다소 복잡한) 오차역전파법은 기울기를 고속으로 구할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
